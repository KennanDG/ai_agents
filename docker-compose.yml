services:
  postgres:
    image: postgres:16
    environment:
      POSTGRES_DB: ai_agents
      POSTGRES_USER: ai_agents
      POSTGRES_PASSWORD: ai_agents
    ports:
      - "5432:5432"
    volumes:
      - pg_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ai_agents -d ai_agents"]
      interval: 5s
      timeout: 5s
      retries: 10
    restart: unless-stopped


  qdrant:
    image: qdrant/qdrant:latest
    ports:
      - "6333:6333" # REST API
      - "6334:6334" # gRPC 
    volumes:
      - qdrant_data:/qdrant/storage
    healthcheck:
      test: ["CMD-SHELL", "wget -qO- http://localhost:6333/healthz || exit 1"]
      interval: 5s
      timeout: 5s
      retries: 10
    restart: unless-stopped


  ollama:
    image: ollama/ollama:latest
    ports:
      - "11434:11434"
    volumes:
      - ollama_data:/root/.ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1          # number of GPUs to use (or 'all')
              capabilities: [gpu]
    restart: unless-stopped
  
  
  adminer:
    image: adminer:latest
    ports:
      - "8080:8080"
    depends_on:
      - postgres


  dev:
    build:
      context: .
      dockerfile: Dockerfile.dev
    working_dir: /workspaces/ai_agents
    volumes:
      - .:/workspaces/ai_agents:cached
    command: sleep infinity
    env_file:
      - .env.docker
    environment:
      PYTHONPATH: /workspaces/ai_agents/src
      OLLAMA_HOST: http://ollama:11434
      QDRANT_URL: http://qdrant:6333
      DATABASE_URL: postgresql+psycopg://ai_agents:ai_agents@postgres:5432/ai_agents
      QDRANT_COLLECTION: rag-default
      CHAT_MODEL: llama3.1:8b
      EMBEDDING_MODEL: nomic-embed-text
      
    depends_on:
      - postgres
      - qdrant
      - ollama


volumes:
  pg_data:
  qdrant_data:
  ollama_data:
