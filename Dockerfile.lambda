FROM public.ecr.aws/lambda/python:3.12

WORKDIR ${LAMBDA_TASK_ROOT}

# 1) Dependency manifests first (cache-friendly)
COPY pyproject.toml uv.lock ./

# 2) Install a pinned uv (deterministic tooling)
RUN python -m pip install --upgrade pip && pip install "uv==0.5.24"

# 3) Export deterministic requirements from uv.lock (no re-resolve)
RUN uv export \
    --format requirements-txt \
    --frozen \
    --no-dev \
    --no-install-project \
    -o requirements.txt


ENV PIP_ONLY_BINARY=:all:

# 4) Install dependencies
RUN pip install --no-cache-dir -r requirements.txt



# -------------------------------------------------------------------
# 5) Bake FastEmbed + HuggingFace caches into the IMAGE (no runtime downloads)
# -------------------------------------------------------------------
# Put caches in /opt so they are part of the built image layers.
ENV FASTEMBED_CACHE_PATH=/opt/fastembed_cache
ENV HF_HOME=/opt/hf
ENV HUGGINGFACE_HUB_CACHE=/opt/hf/hub
ENV TRANSFORMERS_CACHE=/opt/hf/transformers

RUN mkdir -p /opt/fastembed_cache /opt/hf/hub /opt/hf/transformers

# Force-download the embedding + reranker models during build.
# Keep it minimal to ensure the weights are fetched.
# RUN python - <<'PY'
# from langchain_community.embeddings.fastembed import FastEmbedEmbeddings

# # Embedding model used by code
# emb = FastEmbedEmbeddings(model_name="nomic-ai/nomic-embed-text-v1.5", max_length=512)
# _ = emb.embed_documents(["warm cache"])
# print("Embedding model baked into image cache.")
# PY


# RUN python - <<'PY'
# from fastembed.rerank.cross_encoder import TextCrossEncoder

# # Reranker model used by RagSettings default
# reranker = TextCrossEncoder(model_name="BAAI/bge-reranker-base")
# _ = list(reranker.rerank("q", ["doc"]))
# print("Reranker model baked into image cache.")
# PY

# 6) Copy source code
COPY src/ai_agents ${LAMBDA_TASK_ROOT}/ai_agents

# 7) Lambda handler
CMD ["ai_agents.api.lambda_handler.handler"]

