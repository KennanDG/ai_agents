from langchain_core.prompts import ChatPromptTemplate
from langsmith import traceable

# =========================
# RETRIEVAL PROMPTS
# =========================

QUERY_EXPANSION_PROMPT = ChatPromptTemplate.from_messages(
    [
        ("system", "You generate search queries for a retrieval system."),
        (
            "user",
            "Rewrite the user question into {n} diverse search queries.\n"
            "Rules:\n"
            "- Keep each query concise (<= 1-2 sentences)\n"
            "- Use different wording or synonyms\n"
            "- Expand acronyms if helpful\n"
            "- Output ONLY a JSON array of strings\n\n"
            "Question: {question}",
        ),
    ]
)



RERANK_PROMPT = ChatPromptTemplate.from_messages(
    [
        ("system", "You are a strict relevance ranker for retrieval."),
        (
            "user",
            "Given a question and passages, score each passage for relevance.\n"
            "Return ONLY a JSON array of objects: "
            '[{"index": <int>, "score": <float 0-10>}] in the SAME order.\n\n'
            "Question: {question}\n\n"
            "Passages:\n{passages}",
        ),
    ]
)




# =========================
# VERIFICATION PROMPTS
# =========================

GRADER_TEMPLATE = """You are a strict grader assessing an answer generated by an AI based on retrieved context.
Your goal is to verify if the answer is:
1. Grounded in the documents (not hallucinated).
2. Relevant to the user's question.
3. Sufficiently answers the user's question.

Given:
CONTEXT:
{context}

QUESTION:
{question}

ANSWER:
{answer}

Return ONLY valid JSON with exactly these keys:
{"score": 1 or 0, "reason": "<short reason>"}
"""

@traceable
def build_grader_prompt() -> ChatPromptTemplate:
    """Build the prompt used for answer verification (groundedness + relevance).

    Notes:
        - The downstream verifier chain expects JSON output.
        - Keep the prompt deterministic: temperature=0 and explicit JSON schema.
    """
    return ChatPromptTemplate.from_template(GRADER_TEMPLATE)



# =========================
# GENERATION PROMPTS
# =========================

RAG_TEMPLATE = """Answer the question based ONLY on the following context:
{context}

Question: {question}
"""

@traceable
def build_rag_prompt() -> ChatPromptTemplate:
    """Build the prompt used for answer generation."""
    return ChatPromptTemplate.from_template(RAG_TEMPLATE)